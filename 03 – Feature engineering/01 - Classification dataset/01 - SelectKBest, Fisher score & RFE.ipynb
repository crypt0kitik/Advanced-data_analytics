{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - SelectKBest, Fisher score & RFE - comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"bank_numeric.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"deposit\", axis=1)\n",
    "y = df[\"deposit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature names for reference\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: SelectKBest (using ANOVA F-statistic)\n",
    "select_kbest = SelectKBest(score_func=f_classif, k=10)\n",
    "X_kbest = select_kbest.fit_transform(X_scaled, y)\n",
    "kbest_features = [feature_names[i] for i in select_kbest.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Fisher Score\n",
    "def fisher_score(X, y):\n",
    "    scores = []\n",
    "    for i in range(X.shape[1]):\n",
    "        num = (np.mean(X[y == 0, i]) - np.mean(X[y == 1, i])) ** 2\n",
    "        denom = np.var(X[y == 0, i]) + np.var(X[y == 1, i])\n",
    "        scores.append(num / denom if denom != 0 else 0)\n",
    "    return np.array(scores)\n",
    "\n",
    "fisher_scores = fisher_score(X_scaled, y)\n",
    "fisher_indices = fisher_scores.argsort()[-10:][::-1]  # Select top 10 features\n",
    "fisher_features = [feature_names[i] for i in fisher_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Recursive Feature Elimination (RFE)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "X_rfe = rfe.fit_transform(X_scaled, y)\n",
    "rfe_features = [feature_names[i] for i in rfe.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SelectKBest FisherScore       RFE\n",
      "0   education    duration       age\n",
      "1     balance    poutcome       job\n",
      "2     housing     contact   balance\n",
      "3        loan    previous   contact\n",
      "4     contact       pdays       day\n",
      "5    duration     housing     month\n",
      "6    campaign     balance  duration\n",
      "7       pdays    campaign  campaign\n",
      "8    previous   education     pdays\n",
      "9    poutcome        loan  poutcome\n"
     ]
    }
   ],
   "source": [
    "# Comparison of Selected Features\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"SelectKBest\": pd.Series(kbest_features),\n",
    "    \"FisherScore\": pd.Series(fisher_features),\n",
    "    \"RFE\": pd.Series(rfe_features)\n",
    "})\n",
    "\n",
    "\n",
    "# Display comparison\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I utilized 3 feautres\n",
    "# to determine which features in the dataset \n",
    "# are the most important or relevant for \n",
    "# predicting your target variable\n",
    "\n",
    "# every tool has own logic\n",
    "# SelectKBest: Picks features based on their statistical \n",
    "# relationship with the target variable \n",
    "# (how strongly each feature correlates with the target)\n",
    "\n",
    "# Fisher Score: Selects features based on how well \n",
    "# they separate different classes in the target\n",
    "# variable (e.g., good vs. bad outcomes).\n",
    "\n",
    "# RFE (Recursive Feature Elimination): \n",
    "# Selects features by considering their \n",
    "# impact on a predictive model's performance \n",
    "# (in this case, a Random Forest classifier)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
